{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cf0a224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8215661103979461\n",
      "[1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 1 1\n",
      " 1 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1\n",
      " 1 1 0 1 1 0 1 1 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1\n",
      " 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0\n",
      " 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0\n",
      " 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1\n",
      " 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0\n",
      " 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1\n",
      " 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      " 1 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1\n",
      " 1 0 1 1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1\n",
      " 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1\n",
      " 0 1 0 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1\n",
      " 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0 1 1\n",
      " 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0\n",
      " 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "x = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.76, random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score=model.score(x_test,y_test)\n",
    "print(score)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5234710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722222222222222\n",
      "[1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0\n",
      " 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 1\n",
      " 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0\n",
      " 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1\n",
      " 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "x = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.23, random_state=42)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score=model.score(x_test,y_test)\n",
    "print(score)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a4fa3d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9355388175888912\n",
      "[0.99 0.74 0.   0.99 0.   0.95 0.07 0.   1.   0.01 0.84 0.01 1.   0.94\n",
      " 0.   0.08 0.   1.   0.96 0.   0.28 0.   0.07 0.   0.28 1.   0.95 1.\n",
      " 0.01 0.1  0.03 0.94 0.13 0.74 0.99 0.99 0.28 0.94 0.96 1.   0.   0.\n",
      " 0.88 0.07 0.   0.02 0.   0.07 0.03 0.84 0.93 0.   0.27 0.01 0.95 0.96\n",
      " 0.04 0.   0.38 0.99 0.95 0.98 0.01 0.84 0.01 0.09 0.99 0.12 0.02 1.\n",
      " 0.2  0.01 0.   1.   0.98 0.96 0.07 0.12 0.08 1.   0.   0.   0.   0.\n",
      " 0.96 0.   0.84 0.06 0.   0.1  0.03 0.   0.96 1.   0.98 0.99 0.12 0.01\n",
      " 0.   0.   0.85 0.08 0.07 0.91 0.   1.   0.   0.96 0.01 0.99 0.38 0.99\n",
      " 1.   0.   0.99 0.98 0.1  0.97 0.88 0.   0.91 0.81 0.   0.   0.87 0.\n",
      " 0.96 0.04 0.2  1.   0.94 0.   0.98 0.85 0.   1.   0.   0.81 1.   0.1\n",
      " 0.99 0.95 1.   0.86 0.95 0.95 0.93 1.   0.09 0.   0.13 0.02 1.   0.99\n",
      " 0.01 0.   0.12 1.   0.02 0.   0.88 0.95 0.08 0.08 0.95 0.91 0.01 0.02\n",
      " 0.92 1.   0.   0.92 0.99 0.   0.99 0.74 1.   0.02 0.07 0.99 1.   0.01\n",
      " 1.   0.27 0.95 0.88 0.99 0.38 0.96 0.99 0.99 0.08 0.   0.27 0.  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "x = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.19, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score=model.score(x_test,y_test)\n",
    "print(score)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2e7497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7766990291262136\n",
      "[1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0\n",
      " 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 0 1\n",
      " 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "x = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score=model.score(x_test,y_test)\n",
    "print(score)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "346f3620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6753246753246753\n",
      "[1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1\n",
      " 0 0 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1\n",
      " 1 1 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 0 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 0 1 1 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 0 0\n",
      " 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1\n",
      " 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 0\n",
      " 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0\n",
      " 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "x = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.45, random_state=42)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score=model.score(x_test,y_test)\n",
    "print(score)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a00231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8219512195121951\n",
      "[1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1\n",
      " 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1\n",
      " 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1\n",
      " 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1\n",
      " 1 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0\n",
      " 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1\n",
      " 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1\n",
      " 0 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0\n",
      " 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0\n",
      " 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1\n",
      " 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1\n",
      " 1 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1\n",
      " 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1\n",
      " 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1\n",
      " 0 0 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1\n",
      " 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0\n",
      " 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suma\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "x = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.8, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score=model.score(x_test,y_test)\n",
    "print(score)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b013196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
